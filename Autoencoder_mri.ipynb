{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder_mri.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0W1oOxrBWQP",
        "outputId": "11bc83b2-0608-4255-ccf7-ceb47d58e64b"
      },
      "source": [
        "cd drive/MyDrive/ds_project2/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ds_project2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SuoKwzKBibp",
        "outputId": "b25e8294-d7de-449e-904b-9f8787e2f9f2"
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " autoencoder        Autoencoder_mri.ipynb       sex.npy\n",
            " autoencoder2_mri   brains.csv                 'smri gan LA5 128.ipynb'\n",
            " autoencoder3_mri  'fmri gan LA5 64.ipynb'      start_project.ipynb\n",
            " autoencoder4_mri   labels.npy                  tensors.npy\n",
            " autoencoder5_mri   preprocessed_mri_data.npy   unrestricted.csv\n",
            " autoencoder_mri    \u001b[0m\u001b[01;34mruns\u001b[0m/                       unrestricted_hcp_freesurfer.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgOHmRMZVazf"
      },
      "source": [
        "### Set up configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVciQtcavq33"
      },
      "source": [
        "# config parameters\n",
        "PRETRAIN = True\n",
        "PATH = 'autoencoder5_mri'\n",
        "SAVE = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4_9Q-n4Vfe1"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8_PS2CPBWCr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import collections\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "import nibabel\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqdCRTTWBWM3",
        "outputId": "cd33e0f4-7be4-4357-88e3-c40af891dbfd"
      },
      "source": [
        "# X, y = np.load('preprocessed_mri_data.npy'), np.load('sex.npy')\n",
        "X, y = np.load('tensors.npy'), np.load('labels.npy')\n",
        "X = X[:, np.newaxis, :, :, :]\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1113, 1, 58, 70, 58) (1113,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBv5oHSSk2Zy"
      },
      "source": [
        "# Classification on flatten data\n",
        "\n",
        "Make classification on initial data for gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsXqgu4DkAOo"
      },
      "source": [
        "from torchvision import datasets, models, transforms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXo3UVUZkC-9",
        "outputId": "3379b54a-d017-41c1-de92-c2419599cf49"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "def accuracy(X_train, y_train, X_val, y_val):\n",
        "  clf = LogisticRegression(random_state=0).fit(X_train.reshape(X_train.shape[0], np.prod(X_train.shape[1:])), y_train)\n",
        "  return clf.predict(X_val.reshape(X_val.shape[0], np.prod(X_val.shape[1:])))\n",
        "\n",
        "print('Accuracy score on initial data', accuracy_score(y_val, accuracy(X_train, y_train, X_val, y_val)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on initial data 0.9327354260089686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnZix-Z4k6IH"
      },
      "source": [
        "## Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTbcRkY3EPmK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E99VxPUB5M_"
      },
      "source": [
        "class MriData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super(MriData, self).__init__()\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q_Srq7VEEw4"
      },
      "source": [
        "\n",
        "train_dataset = MriData(X_train, y_train)\n",
        "test_dataset = MriData(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=45, shuffle=True) \n",
        "val_loader = DataLoader(test_dataset, batch_size=28, shuffle=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb0j1qxhpPjD",
        "outputId": "7e5f8c8d-9b96-4d85-d4c5-89f371ac9b65"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(890, 1, 58, 70, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEaooiV3i1nz"
      },
      "source": [
        "n_features = 16\n",
        "n_outputs = 1000"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOQkAWr9oM25"
      },
      "source": [
        "# both discriminator and standard classifier (with different number of outputs)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, n_features=n_features, n_outputs=n_outputs):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.main = nn.ModuleList([\n",
        "            nn.Conv3d(1, n_features, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv3d(n_features, n_features * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm3d(n_features * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv3d(n_features * 2, n_features * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm3d(n_features * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv3d(n_features * 4, n_features * 8, kernel_size=4, stride=2, padding=1, bias=False)])\n",
        "        self.main2 = nn.ModuleList([\n",
        "            nn.BatchNorm3d(n_features * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(4608, n_outputs), # outputs logits\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(len(self.main)):\n",
        "            # print()\n",
        "            x = self.main[i](x)\n",
        "        shape = x.shape\n",
        "        for i in range(len(self.main2)):\n",
        "            # print()\n",
        "            x = self.main2[i](x)\n",
        "        return x, shape"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J2aierfoK91"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, n_outputs=n_outputs, n_features=n_features):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.latent_size = n_outputs\n",
        "        self.main = nn.ModuleList([                      \n",
        "            nn.ConvTranspose3d(n_features * 8, n_features * 4, kernel_size=4, stride=2, padding=1,output_padding=(1, 0, 1), bias=False),\n",
        "            nn.BatchNorm3d(n_features * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(n_features * 4, n_features * 2, kernel_size=4, stride=2, padding=1, output_padding=(0, 1, 0),bias=False),\n",
        "            nn.BatchNorm3d(n_features * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(n_features * 2, n_features, kernel_size=4, stride=2, padding=1, output_padding=(1, 1, 1), bias=False),\n",
        "            nn.BatchNorm3d(n_features),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(n_features, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(len(self.main)):\n",
        "            x = self.main[i](x)\n",
        "        return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4rGC-FVs3Yv"
      },
      "source": [
        "encoder = Encoder(n_features, n_outputs)\n",
        "decoder = Decoder(n_outputs, n_features)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCdC1U3ol3UC"
      },
      "source": [
        "class MyFirstAE(nn.Module):\n",
        "    def __init__(self, encoder, decoder, n_outputs):\n",
        "        super(MyFirstAE, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.n_outputs = n_outputs\n",
        "        self.fc = nn.Linear(n_outputs, 4608)\n",
        "        self.decoder = decoder\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Take a mini-batch as an input, encode it to the latent space and decode back to the original space\n",
        "        x_out = decoder(encoder(x))\n",
        "        :param x: torch.tensor, (MB, x_dim)\n",
        "        :return: torch.tensor, (MB, x_dim)\n",
        "        \"\"\"\n",
        "        enc, shape = self.encoder(x)\n",
        "        x = self.fc(enc)\n",
        "        x = x.reshape(shape)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvwaOwPilY67"
      },
      "source": [
        "device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net = MyFirstAE(encoder, decoder, n_outputs)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: 0.95) \n",
        "if PRETRAIN:\n",
        "  net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9WDJIjAVv-B"
      },
      "source": [
        "# Set up tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qQ98hGXlY4i"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "Jq6BuJnAlY21",
        "outputId": "cb6d0aa8-dfec-4569-a6d6-00e30612f2e0"
      },
      "source": [
        "%tensorboard --logdir runs"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 231), started 3:40:36 ago. (Use '!kill 231' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VchPbBdWV1I3"
      },
      "source": [
        "# Train model and the save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqRgM_ROlYz6"
      },
      "source": [
        "def train(epochs, net, criterion, optimizer, train_loader, val_loader,scheduler=None, verbose=True, save_dir=None):\n",
        "    \n",
        "    freq = 3\n",
        "    net.to(device)\n",
        "    \n",
        "    for epoch in range(1, epochs+1):\n",
        "        net.train()\n",
        "\n",
        "        losses_train = []\n",
        "        for X, _ in train_loader:\n",
        "            # Perform one step of minibatch stochastic gradient descent\n",
        "            X = X.to(device)\n",
        "            predicts = net.forward(X)\n",
        "            loss = criterion(predicts, X)\n",
        "            losses_train.append(loss)   \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()  \n",
        "            print(loss) \n",
        "            writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        # define NN evaluation, i.e. turn off dropouts, batchnorms, etc.\n",
        "        net.eval()\n",
        "        for X, _ in val_loader:\n",
        "            X = X.to(device)\n",
        "            losses_val = []\n",
        "            # Compute the validation loss\n",
        "            predicts = net.forward(X)\n",
        "            loss = criterion(predicts, X)\n",
        "            losses_val.append(loss)\n",
        "            writer.add_scalar(\"Loss/test\", loss, epoch)\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "        if verbose and epoch%freq==0:\n",
        "            mean_val = sum(losses_val)/len(losses_val)\n",
        "            mean_train = sum(losses_train)/len(losses_train)\n",
        "\n",
        "            print('Epoch {}/{} || Loss:  Train {:.4f} | Validation {:.4f}'\\\n",
        "                  .format(epoch, epochs, mean_train, mean_val))\n",
        "    writer.close()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IktsaaaQkDBT",
        "outputId": "ba993871-4dc6-45eb-84c4-e44823bb193a"
      },
      "source": [
        "train(20, net, criterion, optimizer, train_loader, val_loader, None) "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2641.5764, grad_fn=<MseLossBackward>)\n",
            "tensor(5700.8159, grad_fn=<MseLossBackward>)\n",
            "tensor(4048.4753, grad_fn=<MseLossBackward>)\n",
            "tensor(3807.1555, grad_fn=<MseLossBackward>)\n",
            "tensor(3299.9104, grad_fn=<MseLossBackward>)\n",
            "tensor(3370.7563, grad_fn=<MseLossBackward>)\n",
            "tensor(3181.8535, grad_fn=<MseLossBackward>)\n",
            "tensor(2930.3218, grad_fn=<MseLossBackward>)\n",
            "tensor(3099.5964, grad_fn=<MseLossBackward>)\n",
            "tensor(2872.1882, grad_fn=<MseLossBackward>)\n",
            "tensor(2936.2539, grad_fn=<MseLossBackward>)\n",
            "tensor(3241.7273, grad_fn=<MseLossBackward>)\n",
            "tensor(2799.4377, grad_fn=<MseLossBackward>)\n",
            "tensor(2727.9268, grad_fn=<MseLossBackward>)\n",
            "tensor(2727.0269, grad_fn=<MseLossBackward>)\n",
            "tensor(2852.3494, grad_fn=<MseLossBackward>)\n",
            "tensor(2643.2708, grad_fn=<MseLossBackward>)\n",
            "tensor(2847.2158, grad_fn=<MseLossBackward>)\n",
            "tensor(2597.9810, grad_fn=<MseLossBackward>)\n",
            "tensor(2755.1333, grad_fn=<MseLossBackward>)\n",
            "tensor(2775.5554, grad_fn=<MseLossBackward>)\n",
            "tensor(2762.9380, grad_fn=<MseLossBackward>)\n",
            "tensor(2582.2820, grad_fn=<MseLossBackward>)\n",
            "tensor(2527.1777, grad_fn=<MseLossBackward>)\n",
            "tensor(2610.4966, grad_fn=<MseLossBackward>)\n",
            "tensor(2685.8228, grad_fn=<MseLossBackward>)\n",
            "tensor(2528.4668, grad_fn=<MseLossBackward>)\n",
            "tensor(2705.3167, grad_fn=<MseLossBackward>)\n",
            "tensor(2372.5400, grad_fn=<MseLossBackward>)\n",
            "tensor(2584.1260, grad_fn=<MseLossBackward>)\n",
            "tensor(2622.3562, grad_fn=<MseLossBackward>)\n",
            "tensor(2436.2139, grad_fn=<MseLossBackward>)\n",
            "tensor(2661.4204, grad_fn=<MseLossBackward>)\n",
            "tensor(2746.6577, grad_fn=<MseLossBackward>)\n",
            "tensor(2602.0986, grad_fn=<MseLossBackward>)\n",
            "tensor(2560.5515, grad_fn=<MseLossBackward>)\n",
            "tensor(2560.7961, grad_fn=<MseLossBackward>)\n",
            "tensor(2496.2029, grad_fn=<MseLossBackward>)\n",
            "tensor(2368.4478, grad_fn=<MseLossBackward>)\n",
            "tensor(2359.9766, grad_fn=<MseLossBackward>)\n",
            "tensor(2390.2400, grad_fn=<MseLossBackward>)\n",
            "tensor(2462.7991, grad_fn=<MseLossBackward>)\n",
            "tensor(2625.4841, grad_fn=<MseLossBackward>)\n",
            "tensor(2628.0454, grad_fn=<MseLossBackward>)\n",
            "tensor(2533.5608, grad_fn=<MseLossBackward>)\n",
            "tensor(2415.5923, grad_fn=<MseLossBackward>)\n",
            "tensor(2390.8572, grad_fn=<MseLossBackward>)\n",
            "tensor(2414.3391, grad_fn=<MseLossBackward>)\n",
            "tensor(2602.6409, grad_fn=<MseLossBackward>)\n",
            "tensor(2663.6238, grad_fn=<MseLossBackward>)\n",
            "tensor(2369.1404, grad_fn=<MseLossBackward>)\n",
            "tensor(2419.6868, grad_fn=<MseLossBackward>)\n",
            "tensor(2419.4138, grad_fn=<MseLossBackward>)\n",
            "tensor(2431.0391, grad_fn=<MseLossBackward>)\n",
            "tensor(2539.3330, grad_fn=<MseLossBackward>)\n",
            "tensor(2492.7886, grad_fn=<MseLossBackward>)\n",
            "tensor(2531.0938, grad_fn=<MseLossBackward>)\n",
            "tensor(2369.7317, grad_fn=<MseLossBackward>)\n",
            "tensor(2406.9612, grad_fn=<MseLossBackward>)\n",
            "tensor(2325.2161, grad_fn=<MseLossBackward>)\n",
            "Epoch 3/20 || Loss:  Train 2471.5791 | Validation 2647.4946\n",
            "tensor(2458.4766, grad_fn=<MseLossBackward>)\n",
            "tensor(2435.2441, grad_fn=<MseLossBackward>)\n",
            "tensor(2433.0347, grad_fn=<MseLossBackward>)\n",
            "tensor(2405.7878, grad_fn=<MseLossBackward>)\n",
            "tensor(2556.3584, grad_fn=<MseLossBackward>)\n",
            "tensor(2368.7820, grad_fn=<MseLossBackward>)\n",
            "tensor(2705.5793, grad_fn=<MseLossBackward>)\n",
            "tensor(2473.6353, grad_fn=<MseLossBackward>)\n",
            "tensor(2454.2261, grad_fn=<MseLossBackward>)\n",
            "tensor(2535.2458, grad_fn=<MseLossBackward>)\n",
            "tensor(2322.2004, grad_fn=<MseLossBackward>)\n",
            "tensor(2362.0718, grad_fn=<MseLossBackward>)\n",
            "tensor(2801.5239, grad_fn=<MseLossBackward>)\n",
            "tensor(2566.7874, grad_fn=<MseLossBackward>)\n",
            "tensor(2418.9106, grad_fn=<MseLossBackward>)\n",
            "tensor(2454.6035, grad_fn=<MseLossBackward>)\n",
            "tensor(2387.4636, grad_fn=<MseLossBackward>)\n",
            "tensor(2370.2903, grad_fn=<MseLossBackward>)\n",
            "tensor(2467.1069, grad_fn=<MseLossBackward>)\n",
            "tensor(2305.5154, grad_fn=<MseLossBackward>)\n",
            "tensor(2313.0649, grad_fn=<MseLossBackward>)\n",
            "tensor(2599.2090, grad_fn=<MseLossBackward>)\n",
            "tensor(2399.5391, grad_fn=<MseLossBackward>)\n",
            "tensor(2504.3594, grad_fn=<MseLossBackward>)\n",
            "tensor(2500.7520, grad_fn=<MseLossBackward>)\n",
            "tensor(2429.0273, grad_fn=<MseLossBackward>)\n",
            "tensor(2291.3560, grad_fn=<MseLossBackward>)\n",
            "tensor(2403.7146, grad_fn=<MseLossBackward>)\n",
            "tensor(2433.8618, grad_fn=<MseLossBackward>)\n",
            "tensor(2380.6621, grad_fn=<MseLossBackward>)\n",
            "tensor(2390.7566, grad_fn=<MseLossBackward>)\n",
            "tensor(2408.5701, grad_fn=<MseLossBackward>)\n",
            "tensor(2460.6433, grad_fn=<MseLossBackward>)\n",
            "tensor(2425.8391, grad_fn=<MseLossBackward>)\n",
            "tensor(2497.7200, grad_fn=<MseLossBackward>)\n",
            "tensor(2769.4099, grad_fn=<MseLossBackward>)\n",
            "tensor(2437.2073, grad_fn=<MseLossBackward>)\n",
            "tensor(2510.3557, grad_fn=<MseLossBackward>)\n",
            "tensor(2568.4312, grad_fn=<MseLossBackward>)\n",
            "tensor(2566.3110, grad_fn=<MseLossBackward>)\n",
            "tensor(2339.2207, grad_fn=<MseLossBackward>)\n",
            "tensor(2450.1763, grad_fn=<MseLossBackward>)\n",
            "tensor(2486.0627, grad_fn=<MseLossBackward>)\n",
            "tensor(2326.3618, grad_fn=<MseLossBackward>)\n",
            "tensor(2382.1580, grad_fn=<MseLossBackward>)\n",
            "tensor(2402.7773, grad_fn=<MseLossBackward>)\n",
            "tensor(2352.8005, grad_fn=<MseLossBackward>)\n",
            "tensor(2264.4868, grad_fn=<MseLossBackward>)\n",
            "tensor(2527.9595, grad_fn=<MseLossBackward>)\n",
            "tensor(2668.0332, grad_fn=<MseLossBackward>)\n",
            "tensor(2597.2004, grad_fn=<MseLossBackward>)\n",
            "tensor(2424.1406, grad_fn=<MseLossBackward>)\n",
            "tensor(2537.3762, grad_fn=<MseLossBackward>)\n",
            "tensor(2366.7058, grad_fn=<MseLossBackward>)\n",
            "tensor(2518.3821, grad_fn=<MseLossBackward>)\n",
            "tensor(2581.5352, grad_fn=<MseLossBackward>)\n",
            "tensor(2530.1826, grad_fn=<MseLossBackward>)\n",
            "tensor(2437.3384, grad_fn=<MseLossBackward>)\n",
            "tensor(2369.2043, grad_fn=<MseLossBackward>)\n",
            "tensor(2470.3638, grad_fn=<MseLossBackward>)\n",
            "Epoch 6/20 || Loss:  Train 2451.6235 | Validation 2745.0408\n",
            "tensor(2434.8274, grad_fn=<MseLossBackward>)\n",
            "tensor(2503.1604, grad_fn=<MseLossBackward>)\n",
            "tensor(2496.9648, grad_fn=<MseLossBackward>)\n",
            "tensor(2494.7676, grad_fn=<MseLossBackward>)\n",
            "tensor(2390.6252, grad_fn=<MseLossBackward>)\n",
            "tensor(2406.2798, grad_fn=<MseLossBackward>)\n",
            "tensor(2704.9485, grad_fn=<MseLossBackward>)\n",
            "tensor(2506.5398, grad_fn=<MseLossBackward>)\n",
            "tensor(2512.9231, grad_fn=<MseLossBackward>)\n",
            "tensor(2459.1775, grad_fn=<MseLossBackward>)\n",
            "tensor(2460.2493, grad_fn=<MseLossBackward>)\n",
            "tensor(2565.8853, grad_fn=<MseLossBackward>)\n",
            "tensor(2362.5144, grad_fn=<MseLossBackward>)\n",
            "tensor(2361.3640, grad_fn=<MseLossBackward>)\n",
            "tensor(2316.9336, grad_fn=<MseLossBackward>)\n",
            "tensor(2204.2161, grad_fn=<MseLossBackward>)\n",
            "tensor(2840.3621, grad_fn=<MseLossBackward>)\n",
            "tensor(2372.7068, grad_fn=<MseLossBackward>)\n",
            "tensor(2416.9829, grad_fn=<MseLossBackward>)\n",
            "tensor(2448.6091, grad_fn=<MseLossBackward>)\n",
            "tensor(2394.2297, grad_fn=<MseLossBackward>)\n",
            "tensor(2421.6545, grad_fn=<MseLossBackward>)\n",
            "tensor(2563.2898, grad_fn=<MseLossBackward>)\n",
            "tensor(2382.8337, grad_fn=<MseLossBackward>)\n",
            "tensor(2631.9092, grad_fn=<MseLossBackward>)\n",
            "tensor(2423.3882, grad_fn=<MseLossBackward>)\n",
            "tensor(2503.2434, grad_fn=<MseLossBackward>)\n",
            "tensor(2399.7180, grad_fn=<MseLossBackward>)\n",
            "tensor(2396.8196, grad_fn=<MseLossBackward>)\n",
            "tensor(2565.3801, grad_fn=<MseLossBackward>)\n",
            "tensor(2488.2622, grad_fn=<MseLossBackward>)\n",
            "tensor(2491.3325, grad_fn=<MseLossBackward>)\n",
            "tensor(2486.8499, grad_fn=<MseLossBackward>)\n",
            "tensor(2433.1665, grad_fn=<MseLossBackward>)\n",
            "tensor(2498.1338, grad_fn=<MseLossBackward>)\n",
            "tensor(2379.4597, grad_fn=<MseLossBackward>)\n",
            "tensor(2534.7559, grad_fn=<MseLossBackward>)\n",
            "tensor(2338.3728, grad_fn=<MseLossBackward>)\n",
            "tensor(2456.2412, grad_fn=<MseLossBackward>)\n",
            "tensor(2346.5161, grad_fn=<MseLossBackward>)\n",
            "tensor(2468.4214, grad_fn=<MseLossBackward>)\n",
            "tensor(2529.3872, grad_fn=<MseLossBackward>)\n",
            "tensor(2372.0603, grad_fn=<MseLossBackward>)\n",
            "tensor(2458.3257, grad_fn=<MseLossBackward>)\n",
            "tensor(2443.3809, grad_fn=<MseLossBackward>)\n",
            "tensor(2480.5691, grad_fn=<MseLossBackward>)\n",
            "tensor(2398.3062, grad_fn=<MseLossBackward>)\n",
            "tensor(2538.0095, grad_fn=<MseLossBackward>)\n",
            "tensor(2422.1211, grad_fn=<MseLossBackward>)\n",
            "tensor(2409.1194, grad_fn=<MseLossBackward>)\n",
            "tensor(2338.8909, grad_fn=<MseLossBackward>)\n",
            "tensor(2371.5474, grad_fn=<MseLossBackward>)\n",
            "tensor(2404.9871, grad_fn=<MseLossBackward>)\n",
            "tensor(2507.1411, grad_fn=<MseLossBackward>)\n",
            "tensor(2251.4355, grad_fn=<MseLossBackward>)\n",
            "tensor(2448.3589, grad_fn=<MseLossBackward>)\n",
            "tensor(2330.4441, grad_fn=<MseLossBackward>)\n",
            "tensor(2594.6272, grad_fn=<MseLossBackward>)\n",
            "tensor(2317.6799, grad_fn=<MseLossBackward>)\n",
            "tensor(2369.8408, grad_fn=<MseLossBackward>)\n",
            "Epoch 9/20 || Loss:  Train 2422.7329 | Validation 2755.2180\n",
            "tensor(2474.8408, grad_fn=<MseLossBackward>)\n",
            "tensor(2405.0193, grad_fn=<MseLossBackward>)\n",
            "tensor(2496.0527, grad_fn=<MseLossBackward>)\n",
            "tensor(2233.4470, grad_fn=<MseLossBackward>)\n",
            "tensor(2622.7983, grad_fn=<MseLossBackward>)\n",
            "tensor(2393.2122, grad_fn=<MseLossBackward>)\n",
            "tensor(2355.2666, grad_fn=<MseLossBackward>)\n",
            "tensor(2383.7695, grad_fn=<MseLossBackward>)\n",
            "tensor(2553.9792, grad_fn=<MseLossBackward>)\n",
            "tensor(2352.6843, grad_fn=<MseLossBackward>)\n",
            "tensor(2408.0393, grad_fn=<MseLossBackward>)\n",
            "tensor(2340.7673, grad_fn=<MseLossBackward>)\n",
            "tensor(2432.7002, grad_fn=<MseLossBackward>)\n",
            "tensor(2733.5479, grad_fn=<MseLossBackward>)\n",
            "tensor(2405.7034, grad_fn=<MseLossBackward>)\n",
            "tensor(2424.3860, grad_fn=<MseLossBackward>)\n",
            "tensor(2494.0688, grad_fn=<MseLossBackward>)\n",
            "tensor(2361.4753, grad_fn=<MseLossBackward>)\n",
            "tensor(2520.3599, grad_fn=<MseLossBackward>)\n",
            "tensor(2472.3230, grad_fn=<MseLossBackward>)\n",
            "tensor(2410.3953, grad_fn=<MseLossBackward>)\n",
            "tensor(2414.0967, grad_fn=<MseLossBackward>)\n",
            "tensor(2460.4365, grad_fn=<MseLossBackward>)\n",
            "tensor(2379.1101, grad_fn=<MseLossBackward>)\n",
            "tensor(2440.9719, grad_fn=<MseLossBackward>)\n",
            "tensor(2351.6111, grad_fn=<MseLossBackward>)\n",
            "tensor(2351.6458, grad_fn=<MseLossBackward>)\n",
            "tensor(2473.7681, grad_fn=<MseLossBackward>)\n",
            "tensor(2552.8196, grad_fn=<MseLossBackward>)\n",
            "tensor(2432.9663, grad_fn=<MseLossBackward>)\n",
            "tensor(2338.5549, grad_fn=<MseLossBackward>)\n",
            "tensor(2528.7725, grad_fn=<MseLossBackward>)\n",
            "tensor(2398.3257, grad_fn=<MseLossBackward>)\n",
            "tensor(2272.3667, grad_fn=<MseLossBackward>)\n",
            "tensor(2635.3250, grad_fn=<MseLossBackward>)\n",
            "tensor(2390.8721, grad_fn=<MseLossBackward>)\n",
            "tensor(2290.9758, grad_fn=<MseLossBackward>)\n",
            "tensor(2399.4614, grad_fn=<MseLossBackward>)\n",
            "tensor(2470.1953, grad_fn=<MseLossBackward>)\n",
            "tensor(2281.4407, grad_fn=<MseLossBackward>)\n",
            "tensor(2416.4229, grad_fn=<MseLossBackward>)\n",
            "tensor(2449.2598, grad_fn=<MseLossBackward>)\n",
            "tensor(2320.8774, grad_fn=<MseLossBackward>)\n",
            "tensor(2294.5283, grad_fn=<MseLossBackward>)\n",
            "tensor(2330.1941, grad_fn=<MseLossBackward>)\n",
            "tensor(2793.0793, grad_fn=<MseLossBackward>)\n",
            "tensor(2390.1421, grad_fn=<MseLossBackward>)\n",
            "tensor(2389.3269, grad_fn=<MseLossBackward>)\n",
            "tensor(2423.7798, grad_fn=<MseLossBackward>)\n",
            "tensor(2356.3958, grad_fn=<MseLossBackward>)\n",
            "tensor(2460.3762, grad_fn=<MseLossBackward>)\n",
            "tensor(2352.3496, grad_fn=<MseLossBackward>)\n",
            "tensor(2472.8645, grad_fn=<MseLossBackward>)\n",
            "tensor(2384.7305, grad_fn=<MseLossBackward>)\n",
            "tensor(2319.5112, grad_fn=<MseLossBackward>)\n",
            "tensor(2502.5801, grad_fn=<MseLossBackward>)\n",
            "tensor(2349.5647, grad_fn=<MseLossBackward>)\n",
            "tensor(2280.8240, grad_fn=<MseLossBackward>)\n",
            "tensor(2281.0247, grad_fn=<MseLossBackward>)\n",
            "tensor(2301.8943, grad_fn=<MseLossBackward>)\n",
            "Epoch 12/20 || Loss:  Train 2393.4866 | Validation 2753.4700\n",
            "tensor(2373.5762, grad_fn=<MseLossBackward>)\n",
            "tensor(2361.5481, grad_fn=<MseLossBackward>)\n",
            "tensor(2432.7795, grad_fn=<MseLossBackward>)\n",
            "tensor(2249.8157, grad_fn=<MseLossBackward>)\n",
            "tensor(2371.5208, grad_fn=<MseLossBackward>)\n",
            "tensor(2282.1003, grad_fn=<MseLossBackward>)\n",
            "tensor(2341.5811, grad_fn=<MseLossBackward>)\n",
            "tensor(2438.1589, grad_fn=<MseLossBackward>)\n",
            "tensor(2495.6614, grad_fn=<MseLossBackward>)\n",
            "tensor(2266.7590, grad_fn=<MseLossBackward>)\n",
            "tensor(2457.6150, grad_fn=<MseLossBackward>)\n",
            "tensor(2455.8860, grad_fn=<MseLossBackward>)\n",
            "tensor(2320.5728, grad_fn=<MseLossBackward>)\n",
            "tensor(2265.1677, grad_fn=<MseLossBackward>)\n",
            "tensor(2278.4619, grad_fn=<MseLossBackward>)\n",
            "tensor(2247.3318, grad_fn=<MseLossBackward>)\n",
            "tensor(2737.1819, grad_fn=<MseLossBackward>)\n",
            "tensor(2353.9592, grad_fn=<MseLossBackward>)\n",
            "tensor(2410.4951, grad_fn=<MseLossBackward>)\n",
            "tensor(2340.2161, grad_fn=<MseLossBackward>)\n",
            "tensor(2350.9172, grad_fn=<MseLossBackward>)\n",
            "tensor(2310.9661, grad_fn=<MseLossBackward>)\n",
            "tensor(2295.4973, grad_fn=<MseLossBackward>)\n",
            "tensor(2499.8000, grad_fn=<MseLossBackward>)\n",
            "tensor(2309.4023, grad_fn=<MseLossBackward>)\n",
            "tensor(2574.8171, grad_fn=<MseLossBackward>)\n",
            "tensor(2502.0100, grad_fn=<MseLossBackward>)\n",
            "tensor(2367.1770, grad_fn=<MseLossBackward>)\n",
            "tensor(2399.2268, grad_fn=<MseLossBackward>)\n",
            "tensor(2508.8074, grad_fn=<MseLossBackward>)\n",
            "tensor(2413.2444, grad_fn=<MseLossBackward>)\n",
            "tensor(2358.1577, grad_fn=<MseLossBackward>)\n",
            "tensor(2501.5837, grad_fn=<MseLossBackward>)\n",
            "tensor(2357.7900, grad_fn=<MseLossBackward>)\n",
            "tensor(2452.3799, grad_fn=<MseLossBackward>)\n",
            "tensor(2478.6821, grad_fn=<MseLossBackward>)\n",
            "tensor(2297.2087, grad_fn=<MseLossBackward>)\n",
            "tensor(2463.2791, grad_fn=<MseLossBackward>)\n",
            "tensor(2271.4900, grad_fn=<MseLossBackward>)\n",
            "tensor(2339.0425, grad_fn=<MseLossBackward>)\n",
            "tensor(2434.2388, grad_fn=<MseLossBackward>)\n",
            "tensor(2462.5945, grad_fn=<MseLossBackward>)\n",
            "tensor(2368.5596, grad_fn=<MseLossBackward>)\n",
            "tensor(2403.7109, grad_fn=<MseLossBackward>)\n",
            "tensor(2494.1626, grad_fn=<MseLossBackward>)\n",
            "tensor(2193.5852, grad_fn=<MseLossBackward>)\n",
            "tensor(2278.4932, grad_fn=<MseLossBackward>)\n",
            "tensor(2384.2239, grad_fn=<MseLossBackward>)\n",
            "tensor(2340.2322, grad_fn=<MseLossBackward>)\n",
            "tensor(2394.3254, grad_fn=<MseLossBackward>)\n",
            "tensor(2428.7446, grad_fn=<MseLossBackward>)\n",
            "tensor(2393.9915, grad_fn=<MseLossBackward>)\n",
            "tensor(2452.2661, grad_fn=<MseLossBackward>)\n",
            "tensor(2349.4724, grad_fn=<MseLossBackward>)\n",
            "tensor(2386.0901, grad_fn=<MseLossBackward>)\n",
            "tensor(2247.7898, grad_fn=<MseLossBackward>)\n",
            "tensor(2367.5459, grad_fn=<MseLossBackward>)\n",
            "tensor(2358.0176, grad_fn=<MseLossBackward>)\n",
            "tensor(2150.3474, grad_fn=<MseLossBackward>)\n",
            "tensor(2506.9407, grad_fn=<MseLossBackward>)\n",
            "Epoch 15/20 || Loss:  Train 2369.7668 | Validation 2741.0935\n",
            "tensor(2242.7764, grad_fn=<MseLossBackward>)\n",
            "tensor(2396.5706, grad_fn=<MseLossBackward>)\n",
            "tensor(2410.0557, grad_fn=<MseLossBackward>)\n",
            "tensor(2318.3059, grad_fn=<MseLossBackward>)\n",
            "tensor(2362.7991, grad_fn=<MseLossBackward>)\n",
            "tensor(2281.1777, grad_fn=<MseLossBackward>)\n",
            "tensor(2310.2366, grad_fn=<MseLossBackward>)\n",
            "tensor(2247.9773, grad_fn=<MseLossBackward>)\n",
            "tensor(2551.7031, grad_fn=<MseLossBackward>)\n",
            "tensor(2351.2075, grad_fn=<MseLossBackward>)\n",
            "tensor(2224.0891, grad_fn=<MseLossBackward>)\n",
            "tensor(2372.4817, grad_fn=<MseLossBackward>)\n",
            "tensor(2379.1838, grad_fn=<MseLossBackward>)\n",
            "tensor(2373.8652, grad_fn=<MseLossBackward>)\n",
            "tensor(2364.7153, grad_fn=<MseLossBackward>)\n",
            "tensor(2330.0862, grad_fn=<MseLossBackward>)\n",
            "tensor(2257.1946, grad_fn=<MseLossBackward>)\n",
            "tensor(2455.0459, grad_fn=<MseLossBackward>)\n",
            "tensor(2416.3254, grad_fn=<MseLossBackward>)\n",
            "tensor(2370.3225, grad_fn=<MseLossBackward>)\n",
            "tensor(2282.3027, grad_fn=<MseLossBackward>)\n",
            "tensor(2376.9153, grad_fn=<MseLossBackward>)\n",
            "tensor(2267.9565, grad_fn=<MseLossBackward>)\n",
            "tensor(2230.7295, grad_fn=<MseLossBackward>)\n",
            "tensor(2303.6443, grad_fn=<MseLossBackward>)\n",
            "tensor(2262.5042, grad_fn=<MseLossBackward>)\n",
            "tensor(2214.6025, grad_fn=<MseLossBackward>)\n",
            "tensor(2332.5938, grad_fn=<MseLossBackward>)\n",
            "tensor(2576.0366, grad_fn=<MseLossBackward>)\n",
            "tensor(2168.0115, grad_fn=<MseLossBackward>)\n",
            "tensor(2334.4268, grad_fn=<MseLossBackward>)\n",
            "tensor(2243.1917, grad_fn=<MseLossBackward>)\n",
            "tensor(2283.3108, grad_fn=<MseLossBackward>)\n",
            "tensor(2279.2808, grad_fn=<MseLossBackward>)\n",
            "tensor(2451.5867, grad_fn=<MseLossBackward>)\n",
            "tensor(2375.7686, grad_fn=<MseLossBackward>)\n",
            "tensor(2451.7161, grad_fn=<MseLossBackward>)\n",
            "tensor(2349.3813, grad_fn=<MseLossBackward>)\n",
            "tensor(2411.5769, grad_fn=<MseLossBackward>)\n",
            "tensor(2588.4272, grad_fn=<MseLossBackward>)\n",
            "tensor(2459.4683, grad_fn=<MseLossBackward>)\n",
            "tensor(2522.1218, grad_fn=<MseLossBackward>)\n",
            "tensor(2447.1155, grad_fn=<MseLossBackward>)\n",
            "tensor(2452.4707, grad_fn=<MseLossBackward>)\n",
            "tensor(2323.1133, grad_fn=<MseLossBackward>)\n",
            "tensor(2201.4780, grad_fn=<MseLossBackward>)\n",
            "tensor(2261.2227, grad_fn=<MseLossBackward>)\n",
            "tensor(2289.8892, grad_fn=<MseLossBackward>)\n",
            "tensor(2316.8572, grad_fn=<MseLossBackward>)\n",
            "tensor(2391.9473, grad_fn=<MseLossBackward>)\n",
            "tensor(2388.4153, grad_fn=<MseLossBackward>)\n",
            "tensor(2355.0125, grad_fn=<MseLossBackward>)\n",
            "tensor(2376.5054, grad_fn=<MseLossBackward>)\n",
            "tensor(2443.3950, grad_fn=<MseLossBackward>)\n",
            "tensor(2236.1467, grad_fn=<MseLossBackward>)\n",
            "tensor(2295.1782, grad_fn=<MseLossBackward>)\n",
            "tensor(2379.2996, grad_fn=<MseLossBackward>)\n",
            "tensor(2194.1963, grad_fn=<MseLossBackward>)\n",
            "tensor(2448.4329, grad_fn=<MseLossBackward>)\n",
            "tensor(2423.7017, grad_fn=<MseLossBackward>)\n",
            "Epoch 18/20 || Loss:  Train 2360.2986 | Validation 2523.8423\n",
            "tensor(2299.9612, grad_fn=<MseLossBackward>)\n",
            "tensor(2277.2493, grad_fn=<MseLossBackward>)\n",
            "tensor(2297.4661, grad_fn=<MseLossBackward>)\n",
            "tensor(2286.4934, grad_fn=<MseLossBackward>)\n",
            "tensor(2297.2493, grad_fn=<MseLossBackward>)\n",
            "tensor(2212.2004, grad_fn=<MseLossBackward>)\n",
            "tensor(2393.6755, grad_fn=<MseLossBackward>)\n",
            "tensor(2289.0403, grad_fn=<MseLossBackward>)\n",
            "tensor(2270.6899, grad_fn=<MseLossBackward>)\n",
            "tensor(2330.8010, grad_fn=<MseLossBackward>)\n",
            "tensor(2204.2759, grad_fn=<MseLossBackward>)\n",
            "tensor(2403.3457, grad_fn=<MseLossBackward>)\n",
            "tensor(2266.4656, grad_fn=<MseLossBackward>)\n",
            "tensor(2386.3955, grad_fn=<MseLossBackward>)\n",
            "tensor(2340.9429, grad_fn=<MseLossBackward>)\n",
            "tensor(2358.8625, grad_fn=<MseLossBackward>)\n",
            "tensor(2309.8208, grad_fn=<MseLossBackward>)\n",
            "tensor(2378.3137, grad_fn=<MseLossBackward>)\n",
            "tensor(2401.8071, grad_fn=<MseLossBackward>)\n",
            "tensor(2345.8975, grad_fn=<MseLossBackward>)\n",
            "tensor(2332.6775, grad_fn=<MseLossBackward>)\n",
            "tensor(2274.8455, grad_fn=<MseLossBackward>)\n",
            "tensor(2372.5410, grad_fn=<MseLossBackward>)\n",
            "tensor(2237.7258, grad_fn=<MseLossBackward>)\n",
            "tensor(2277.0781, grad_fn=<MseLossBackward>)\n",
            "tensor(2190.4319, grad_fn=<MseLossBackward>)\n",
            "tensor(2230.2036, grad_fn=<MseLossBackward>)\n",
            "tensor(2697.7339, grad_fn=<MseLossBackward>)\n",
            "tensor(2346.8965, grad_fn=<MseLossBackward>)\n",
            "tensor(2370.0098, grad_fn=<MseLossBackward>)\n",
            "tensor(2368.2759, grad_fn=<MseLossBackward>)\n",
            "tensor(2513.8584, grad_fn=<MseLossBackward>)\n",
            "tensor(2195.7468, grad_fn=<MseLossBackward>)\n",
            "tensor(2324.4055, grad_fn=<MseLossBackward>)\n",
            "tensor(2311.3923, grad_fn=<MseLossBackward>)\n",
            "tensor(2310.2866, grad_fn=<MseLossBackward>)\n",
            "tensor(2426.5776, grad_fn=<MseLossBackward>)\n",
            "tensor(2275.3687, grad_fn=<MseLossBackward>)\n",
            "tensor(2379.5198, grad_fn=<MseLossBackward>)\n",
            "tensor(2174.4624, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oenio8HWthXu"
      },
      "source": [
        "# if SAVE:  \n",
        "torch.save(net.state_dict(), 'autoencoder5_mri')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR2l3U7wV9WZ"
      },
      "source": [
        "# Model inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn7hlxJ7kDEo"
      },
      "source": [
        "net.eval()\n",
        "latent_train, shape_train = net.encoder(torch.tensor(X_train, dtype=torch.float))\n",
        "latent_test, shape_test = net.encoder(torch.tensor(X_val, dtype=torch.float))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-jyJQuuWBgl"
      },
      "source": [
        "# Classification on latent data\n",
        "\n",
        "Make classification on latent data for gender and compare obtained results with classification score on initial data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztk3EHEmnz-c",
        "outputId": "f1c4eb81-3617-497a-b3ae-4540698701ba"
      },
      "source": [
        "print('Accuracy score on latent data', accuracy_score(y_val, accuracy(latent_train.detach().numpy(), y_train, latent_test.detach().numpy(), y_val)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on latent data 0.9327354260089686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk11v4HKYtCL"
      },
      "source": [
        "# Create vectors of average women and men brains"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_0UQpObn0Dn"
      },
      "source": [
        "preds = accuracy(latent_train.detach().numpy(), y_train, latent_test.detach().numpy(), y_val)\n",
        "# index of man and women\n",
        "idx1 = np.where(preds==1)[0]\n",
        "idx0 = np.where(preds==0)[0]\n",
        "# mean latent vector of men and women brain\n",
        "mean_m = latent_test[idx0, :].mean(axis=0)\n",
        "mean_w = latent_test[idx1, :].mean(axis=0)\n",
        "# decode values\n",
        "decoded_m = net.decoder(torch.tensor(net.fc(mean_m).reshape(shape_test[1:]).unsqueeze(0), dtype=torch.float)).detach().numpy()\n",
        "decoded_w = net.decoder(torch.tensor(net.fc(mean_w).reshape(shape_test[1:]).unsqueeze(0), dtype=torch.float)).detach().numpy()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pNcL2Crn0I8"
      },
      "source": [
        "mean_brains = []\n",
        "mean_brains.append(list(decoded_m[0]))\n",
        "mean_brains.append(list(decoded_w[0]))\n",
        "\n",
        "brain = pd.DataFrame(mean_brains, columns=list(X_tr.columns), index=['man', 'women'])\n",
        "brain.to_csv(\"brain_mri.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "othr_wVZfIf5"
      },
      "source": [
        "# Classification for age on initial and latent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8QEpiGoepcX"
      },
      "source": [
        "age_labels = pd.read_csv('age.csv')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2tuTU1Ze4Ih"
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(age_labels)\n",
        "y_age = le.transform(age_labels)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWXtL7SHfunk",
        "outputId": "967365e6-8fba-4659-c60c-3e751f3b60d0"
      },
      "source": [
        "np.unique(y_age, return_counts=True)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3]), array([231, 486, 383,  13]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvPiJ1HLjOCS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmG8LlAIgheA",
        "outputId": "d753ce6d-a89a-4519-f8ef-e1180186a2ab"
      },
      "source": [
        "age_labels.value_counts()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age  \n",
              "26-30    486\n",
              "31-35    383\n",
              "22-25    231\n",
              "36+       13\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n53XrPJhz0K"
      },
      "source": [
        "# from sklearn.model_selection import cross_validate\n",
        "# from sklearn.multiclass import OneVsRestClassifier\n",
        "# from sklearn.multiclass import OneVsOneClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIMIm_cVffKR"
      },
      "source": [
        "# X_train_age, X_val_age, y_train_age, y_val_age = train_test_split(X, y_age, test_size=0.2, stratify=y_age, random_state=42)"
      ],
      "execution_count": 55,
      "outputs": []
    }
  ]
}