{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overhead-charter",
   "metadata": {
    "id": "overhead-charter"
   },
   "source": [
    "In this notebook, we try to\n",
    "\n",
    "- train classificator on real 3D MRI brain images and corresponding gender labels \n",
    "- after that, we use previously synthesized images to predict gender labels for them\n",
    "- finally, we train a simple logistic regression on latent representations of synthesized images to fit labels, predicted on previous step\n",
    "\n",
    "Then, for a real image from initial dataset, we can get its modification which would be classified more as man or a woman. With that, patterns connected to this data fluctuation would be visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "seasonal-wells",
   "metadata": {
    "id": "seasonal-wells"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "restricted-asbestos",
   "metadata": {
    "id": "restricted-asbestos"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as torch_data\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "attended-character",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "attended-character",
    "outputId": "f25249c0-e0cb-47d2-c969-a4aa16ed5309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "everyday-killer",
   "metadata": {
    "id": "everyday-killer"
   },
   "outputs": [],
   "source": [
    "class MRIData(torch_data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(MRIData, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "        data_min = self.X.min(axis=(2, 3, 4))\n",
    "        data_max = self.X.max(axis=(2, 3, 4))\n",
    "        data_max[data_max == 0.] = 1.\n",
    "        dif = data_max - data_min\n",
    "\n",
    "        self.X = (self.X - data_min[..., None, None, None]) / dif[..., None, None, None]\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changing-compatibility",
   "metadata": {
    "id": "changing-compatibility"
   },
   "outputs": [],
   "source": [
    "mri_data = np.load('tensors.npy')\n",
    "labels = np.load('sex.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "according-shadow",
   "metadata": {
    "id": "according-shadow"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "data_train, data_val, y_train, y_val = train_test_split(mri_data, labels,\n",
    "                                                        test_size=0.2)\n",
    "\n",
    "data_train = np.pad(data_train, ((0, 0), (6, 6), (0, 0), (6, 6)))\n",
    "data_train = data_train.reshape(-1, 1, 70, 70, 70)\n",
    "\n",
    "data_val = np.pad(data_val, ((0, 0), (6, 6), (0, 0), (6, 6)))\n",
    "data_val = data_val.reshape(-1, 1, 70, 70, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surprising-enzyme",
   "metadata": {
    "id": "surprising-enzyme"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dset = MRIData(data_train, y_train)\n",
    "test_dset = MRIData(data_val, y_val)\n",
    "\n",
    "train_loader = torch_data.DataLoader(train_dset, batch_size=10, shuffle=True)\n",
    "test_loader = torch_data.DataLoader(test_dset, batch_size=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7-7yiLQsgK3",
   "metadata": {
    "id": "a7-7yiLQsgK3"
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, use_bn=True, padding=1, kernel_size=3):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        if use_bn:\n",
    "          self.bn1 = nn.BatchNorm3d(in_channels)\n",
    "          self.bn2 = nn.BatchNorm3d(in_channels // 2)\n",
    "        else:\n",
    "          self.bn1 = Identity()\n",
    "          self.bn2 = Identity()\n",
    "        \n",
    "        self.conv0 = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv1 = nn.Conv3d(in_channels, in_channels // 2, kernel_size=3, padding=padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv3d(in_channels // 2, out_channels, kernel_size=3, padding=padding)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.conv0(x)\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(x)\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out += identity\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "naughty-paintball",
   "metadata": {
    "id": "naughty-paintball"
   },
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.view(batch_size, -1)\n",
    "    \n",
    "\n",
    "class FC_Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, n_classes):\n",
    "        super(FC_Classifier, self).__init__()\n",
    "        \n",
    "        n = 8\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels, n * 2, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(n * 2)\n",
    "        self.conv2 = ResBlock(n * 2, n * 4, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(n * 4)\n",
    "        self.conv3 = ResBlock(n * 4, n * 8, kernel_size=3, padding=1)\n",
    "        self.act = nn.ReLU()\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.dropout = nn.Dropout3d()\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = nn.Linear((8 ** 3) * n * 8, 200)\n",
    "        self.bn3 = nn.BatchNorm1d(200)\n",
    "        self.linear2 = nn.Linear(200, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # x = self.bn1(x)\n",
    "        # x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        # x = self.bn2(x)\n",
    "        # x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        # x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lasting-accuracy",
   "metadata": {
    "id": "lasting-accuracy"
   },
   "outputs": [],
   "source": [
    "classifier = FC_Classifier(in_channels=1, n_classes=1)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "classifier.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  \n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=5e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "about-audit",
   "metadata": {
    "id": "about-audit"
   },
   "outputs": [],
   "source": [
    "def train_classifier(classifier, criterion, optimizer, train_loader, test_loader, n_epochs=50):\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        classifier.train()\n",
    "\n",
    "        losses_train = []\n",
    "        \n",
    "        for X, target in train_loader:\n",
    "            if len(X) > 1:\n",
    "              X, target = X.to(device), target.to(device)\n",
    "              target = target.float().reshape(-1, 1)\n",
    "              \n",
    "              \n",
    "              optimizer.zero_grad()\n",
    "              \n",
    "              logits = classifier(X)\n",
    "              loss = criterion(logits, target)\n",
    "              losses_train.append(loss.detach().cpu().numpy())\n",
    "\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            \n",
    "            y_pred_val =  []\n",
    "            y_true_val = []\n",
    "\n",
    "            classifier.eval()\n",
    "            \n",
    "            losses_val = []\n",
    "            \n",
    "            for X, target in test_loader:\n",
    "                X, target = X.to(device), target.to(device)\n",
    "                target = target.float().reshape(-1, 1)\n",
    "\n",
    "                logits = classifier(X)\n",
    "                val_loss = criterion(logits, target)\n",
    "                losses_val.append(val_loss.detach().cpu().numpy())\n",
    "                \n",
    "                target_hat_val = torch.sigmoid(logits)\n",
    "                target_hat_val = target_hat_val > 0.5\n",
    "                target_hat_val = target_hat_val.float()\n",
    "\n",
    "                y_pred_val.extend(target_hat_val.tolist())\n",
    "                y_true_val.extend(target.tolist())\n",
    "\n",
    "            mean_val = sum(losses_val) / len(losses_val)\n",
    "            mean_train = sum(losses_train) / len(losses_train)\n",
    "\n",
    "            print('Val epoch {}'.format(epoch), \\\n",
    "              ', Loss : {:.3}'.format(mean_train), \\\n",
    "              ', Accuracy on test: {:.3}'.format(accuracy_score(y_true_val, y_pred_val)) )\n",
    "            \n",
    "            torch.save(classifier.state_dict(), 'gender_classifier_checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "TJrIKYCCq3lR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJrIKYCCq3lR",
    "outputId": "81f262d9-1257-4cc1-d9d6-24cc70e8bb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 5 , Loss : 0.355 , Accuracy on test: 0.879\n",
      "Val epoch 10 , Loss : 0.319 , Accuracy on test: 0.937\n",
      "Val epoch 15 , Loss : 0.246 , Accuracy on test: 0.942\n",
      "Val epoch 20 , Loss : 0.194 , Accuracy on test: 0.919\n",
      "Val epoch 25 , Loss : 0.174 , Accuracy on test: 0.969\n",
      "Val epoch 30 , Loss : 0.154 , Accuracy on test: 0.969\n",
      "Val epoch 35 , Loss : 0.0972 , Accuracy on test: 0.964\n",
      "Val epoch 40 , Loss : 0.0972 , Accuracy on test: 0.955\n",
      "Val epoch 45 , Loss : 0.134 , Accuracy on test: 0.928\n",
      "Val epoch 50 , Loss : 0.0766 , Accuracy on test: 0.946\n"
     ]
    }
   ],
   "source": [
    " train_classifier(classifier, criterion, optimizer, train_loader, test_loader, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TbiPXtvSJEcl",
   "metadata": {
    "id": "TbiPXtvSJEcl"
   },
   "source": [
    "Load all previously trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "EtGEvjPE3FsR",
   "metadata": {
    "id": "EtGEvjPE3FsR"
   },
   "outputs": [],
   "source": [
    "from models import Generator3D_Adaptive, Encoder\n",
    "from utils import plot_central_cuts, Fake_MRIData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0g_XRH18DpsM",
   "metadata": {
    "id": "0g_XRH18DpsM"
   },
   "outputs": [],
   "source": [
    "generator = Generator3D_Adaptive()\n",
    "encoder = Encoder()\n",
    "classifier = FC_Classifier(in_channels=1, n_classes=1)\n",
    "\n",
    "generator.load_state_dict(torch.load('generator_checkpoint.pth'))\n",
    "encoder.load_state_dict(torch.load('encoder_checkpoint.pth'))\n",
    "classifier.load_state_dict(torch.load('gender_classifier_checkpoint.pth'))\n",
    "\n",
    "\n",
    "generator.eval()\n",
    "encoder.eval()\n",
    "classifier.eval();\n",
    "#generator.to(device)\n",
    "#encoder.to(device)\n",
    "#classifier.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CB-Hw7k5KOUa",
   "metadata": {
    "id": "CB-Hw7k5KOUa"
   },
   "source": [
    "Load images, synthesized by generator, and its corresponding latent representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "vbJtSB_9EXla",
   "metadata": {
    "id": "vbJtSB_9EXla"
   },
   "outputs": [],
   "source": [
    "fake_data = np.load('fake_data.npy')\n",
    "latent_repr = np.load('latent_repr.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pUDbTuZlFz-F",
   "metadata": {
    "id": "pUDbTuZlFz-F"
   },
   "outputs": [],
   "source": [
    "fake_dset = Fake_MRIData(fake_data, latent_repr)\n",
    "\n",
    "fake_data_loader = torch_data.DataLoader(fake_dset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80SmC5gpKi03",
   "metadata": {
    "id": "80SmC5gpKi03"
   },
   "source": [
    "Predict genders for synthesized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7hAYD4HmFR2M",
   "metadata": {
    "id": "7hAYD4HmFR2M"
   },
   "outputs": [],
   "source": [
    "fake_gender_labels = np.array([])\n",
    "\n",
    "for imgs, _ in fake_data_loader:\n",
    "  logits = classifier(imgs)\n",
    "\n",
    "  gender_labels = torch.sigmoid(logits)\n",
    "  gender_labels = gender_labels > 0.5\n",
    "  gender_labels = gender_labels.float()\n",
    "\n",
    "  fake_gender_labels = np.concatenate((fake_gender_labels, gender_labels.detach().numpy().reshape(-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "EiDgbsmEFleb",
   "metadata": {
    "id": "EiDgbsmEFleb"
   },
   "outputs": [],
   "source": [
    "np.save('fake_gender_labels.npy', fake_gender_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "BO21xRdjIPxE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BO21xRdjIPxE",
    "outputId": "bf6b3877-22fc-46af-ea81-2cc852dd7aa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_gender_labels.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-KEzg1KtW1nE",
   "metadata": {
    "id": "-KEzg1KtW1nE"
   },
   "source": [
    "Unfortunately, it looks like fake images, synthesized by generator, are too poor quality for the classifier to retrieve necessary features from them. Though many efforts were applied to train a stable generator, there should be a lot more precise tuning of both models to work together well, which is impossible for our time frames    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN_experiment_part2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
